{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Mr. Speaker, Mr. Vice President, Members of Congress, my fellow Americans:\\n\\nTonight marks the eighth year that I’ve come here to report on the State of the Union. And for this final one, I’m going to try to make it a little shorter. (Applause.) I know some of you are antsy to get back to Iowa. (Laughter.) I've been there. I'll be shaking hands afterwards if you want some tips. (Laughter.)\\n\\nAnd I understand that because it’s an election season, expectations for what we will achieve this year are low. But, Mr. Speaker, I appreciate the constructive approach that you and the other leaders took at the end of last year to pass a budget and make tax cuts permanent for working families. So I hope we can work together this year on some bipartisan priorities like criminal justice reform -- (applause) -- and helping people who are battling prescription drug abuse and heroin abuse. (Applause.) So, who knows, we might surprise the cynics again.\\n\\nBut tonight, I want to go easy on the traditional list of proposals for the year ahead. Don’t worry, I’ve got plenty, from helping students learn to write computer code to personalizing medical treatments for patients. And I will keep pushing for progress on the work that I believe still needs to be done. Fixing a broken immigration system. (Applause.) Protecting our kids from gun violence. (Applause.) Equal pay for equal work. (Applause.) Paid leave. (Applause.) Raising the minimum wage. (Applause.) All these things still matter to hardworking families. They’re still the right thing to do. And I won't let up until they get done.\\n\\nBut for my final address to this chamber, I don’t want to just talk about next year. I want to focus on the next five years, the next 10 years, and beyond. I want to focus on our future.\\n\\nWe live in a time of extraordinary change -- change that’s reshaping the way we live, the way we work, our planet, our place in the world. It’s change that promises amazing medical breakthroughs, but also economic disruptions that strain working families. It promises education for girls in the most remote villages, but also connects terrorists plotting an ocean away. It’s change that can broaden opportunity, or widen inequality. And whether we like it or not, the pace of this change will only accelerate.\\n\\nAmerica has been through big changes before -- wars and depression, the influx of new immigrants, workers fighting for a fair deal, movements to expand civil rights. Each time, there have been those who told us to fear the future; who claimed we could slam the brakes on change; who promised to restore past glory if we just got some group or idea that was threatening America under control. And each time, we overcame those fears. We did not, in the words of Lincoln, adhere to the “dogmas of the quiet past.” Instead we thought anew, and acted anew. We made change work for us, always extending America’s promise outward, to the next frontier, to more people. And because we did -- because we saw opportunity where others saw only peril -- we emerged stronger and better than before.\\n\\nWhat was true then can be true now. Our unique strengths as a nation -- our optimism and work ethic, our spirit of discovery, our diversity, our commitment to rule of law -- these things give us everything we need to ensure prosperity and security for generations to come.\\n\\nIn fact, it’s that spirit that made the progress of these past seven years possible.  It’s how we recovered from the worst economic crisis in generations.  It’s how we reformed our health care system, and reinvented our energy sector; how we delivered more care and benefits to our troops and veterans, and how we secured the freedom in every state to marry the person we love.\\n\\nBut such progress is not inevitable. It’s the result of choices we make together. And we face such choices right now. Will we respond to the changes of our time with fear, turning inward as a nation, turning against each other as a people? Or will we face the future with confidence in who we are, in what we stand for, in the incredible things that we can do together?\\n\\nSo let’s talk about the future, and four big questions that I believe we as a country have to answer -- regardless of who the next President is, or who controls the next Congress.\\n\\nFirst, how do we give everyone a fair shot at opportunity and security in this new economy? (Applause.)\\n\\nSecond, how do we make technology work for us, and not against us -- especially when it comes to solving urgent challenges like climate change? (Applause.)\\n\\nThird, how do we keep America safe and lead the world without becoming its policeman? (Applause.)\\n\\nAnd finally, how can we make our politics reflect what’s best in us, and not what’s worst?\\n\\nLet me start with the economy, and a basic fact: The United States of America, right now, has the strongest, most durable economy in the world. (Applause.) We’re in the middle of the longest streak of private sector job creation in history. (Applause.) More than 14 million new jobs, the strongest two years of job growth since the ‘90s, an unemployment rate cut in half. Our auto industry just had its best year ever. (Applause.) That's just part of a manufacturing surge that's created nearly 900,000 new jobs in the past six years. And we’ve done all this while cutting our deficits by almost three-quarters. (Applause.)\\n\\nAnyone claiming that America’s economy is in decline is peddling fiction. (Applause.) Now, what is true -- and the reason that a lot of Americans feel anxious -- is that the economy has been changing in profound ways, changes that started long before the Great Recession hit; changes that have not let up.\\n\\nToday, technology doesn’t just replace jobs on the assembly line, but any job where work can be automated. Companies in a global economy can locate anywhere, and they face tougher competition. As a result, workers have less leverage for a raise. Companies have less loyalty to their communities. And more and more wealth and income is concentrated at the very top.\\n\\nAll these trends have squeezed workers, even when they have jobs; even when the economy is growing. It’s made it harder for a hardworking family to pull itself out of poverty, harder for young people to start their careers, tougher for workers to retire when they want to. And although none of these trends are unique to America, they do offend our uniquely American belief that everybody who works hard should get a fair shot.\\n\\nFor the past seven years, our goal has been a growing economy that works also better for everybody. We’ve made progress. But we need to make more. And despite all the political arguments that we’ve had these past few years, there are actually some areas where Americans broadly agree.\\n\\nWe agree that real opportunity requires every American to get the education and training they need to land a good-paying job. The bipartisan reform of No Child Left Behind was an important start, and together, we’ve increased early childhood education, lifted high school graduation rates to new highs, boosted graduates in fields like engineering. In the coming years, we should build on that progress, by providing Pre-K for all and -- (applause) -- offering every student the hands-on computer science and math classes that make them job-ready on day one. We should recruit and support more great teachers for our kids. (Applause.)\\n\\nAnd we have to make college affordable for every American. (Applause.) No hardworking student should be stuck in the red. We’ve already reduced student loan payments to 10 percent of a borrower’s income. And that's good. But now, we’ve actually got to cut the cost of college. (Applause.) Providing two years of community college at no cost for every responsible student is one of the best ways to do that, and I’m going to keep fighting to get that started this year. (Applause.) It's the right thing to do. (Applause.)\\n\\nBut a great education isn’t all we need in this new economy. We also need benefits and protections that provide a basic measure of security. It’s not too much of a stretch to say that some of the only people in America who are going to work the same job, in the same place, with a health and retirement package for 30 years are sitting in this chamber. (Laughter.) For everyone else, especially folks in their 40s and 50s, saving for retirement or bouncing back from job loss has gotten a lot tougher. Americans understand that at some point in their careers, in this new economy, they may have to retool and they may have to retrain. But they shouldn’t lose what they’ve already worked so hard to build in the process.\\n\\nThat’s why Social Security and Medicare are more important than ever. We shouldn’t weaken them; we should strengthen them. (Applause.) And for Americans short of retirement, basic benefits should be just as mobile as everything else is today. That, by the way, is what the Affordable Care Act is all about. It’s about filling the gaps in employer-based care so that when you lose a job, or you go back to school, or you strike out and launch that new business, you’ll still have coverage. Nearly 18 million people have gained coverage so far. (Applause.) And in the process, health care inflation has slowed. And our businesses have created jobs every single month since it became law.\\n\\nNow, I’m guessing we won’t agree on health care anytime soon. (Applause.) A little applause right there. (Laughter.) Just a guess. But there should be other ways parties can work together to improve economic security. Say a hardworking American loses his job -- we shouldn’t just make sure that he can get unemployment insurance; we should make sure that program encourages him to retrain for a business that’s ready to hire him. If that new job doesn’t pay as much, there should be a system of wage insurance in place so that he can still pay his bills. And even if he’s going from job to job, he should still be able to save for retirement and take his savings with him. That’s the way we make the new economy work better for everybody.\\n\\nI also know Speaker Ryan has talked about his interest in tackling poverty. America is about giving everybody willing to work a chance, a hand up. And I’d welcome a serious discussion about strategies we can all support, like expanding tax cuts for low-income workers who don't have children. (Applause.)\\n\\nBut there are some areas where we just have to be honest -- it has been difficult to find agreement over the last seven years. And a lot of them fall under the category of what role the government should play in making sure the system’s not rigged in favor of the wealthiest and biggest corporations. (Applause.) And it's an honest disagreement, and the American people have a choice to make.\\n\\nI believe a thriving private sector is the lifeblood of our economy. I think there are outdated regulations that need to be changed. There is red tape that needs to be cut. (Applause.) There you go! Yes! (Applause.) But after years now of record corporate profits, working families won’t get more opportunity or bigger paychecks just by letting big banks or big oil or hedge funds make their own rules at everybody else’s expense. (Applause.) Middle-class families are not going to feel more secure because we allowed attacks on collective bargaining to go unanswered. Food Stamp recipients did not cause the financial crisis; recklessness on Wall Street did. (Applause.) Immigrants aren’t the principal reason wages haven’t gone up; those decisions are made in the boardrooms that all too often put quarterly earnings over long-term returns. It’s sure not the average family watching tonight that avoids paying taxes through offshore accounts. (Applause.)\\n\\nThe point is, I believe that in this new economy, workers and start-ups and small businesses need more of a voice, not less. The rules should work for them. (Applause.) And I'm not alone in this. This year I plan to lift up the many businesses who’ve figured out that doing right by their workers or their customers or their communities ends up being good for their shareholders. (Applause.) And I want to spread those best practices across America. That's part of a brighter future. (Applause.)\\n\\nIn fact, it turns out many of our best corporate citizens are also our most creative. And this brings me to the second big question we as a country have to answer: How do we reignite that spirit of innovation to meet our biggest challenges?\\n\\nSixty years ago, when the Russians beat us into space, we didn’t deny Sputnik was up there. (Laughter.) We didn’t argue about the science, or shrink our research and development budget. We built a space program almost overnight. And 12 years later, we were walking on the moon. (Applause.)\\n\\nNow, that spirit of discovery is in our DNA. America is Thomas Edison and the Wright Brothers and George Washington Carver. America is Grace Hopper and Katherine Johnson and Sally Ride. America is every immigrant and entrepreneur from Boston to Austin to Silicon Valley, racing to shape a better world. (Applause.) That's who we are.\\n\\nAnd over the past seven years, we’ve nurtured that spirit. We’ve protected an open Internet, and taken bold new steps to get more students and low-income Americans online. (Applause.) We’ve launched next-generation manufacturing hubs, and online tools that give an entrepreneur everything he or she needs to start a business in a single day. But we can do so much more.\\n\\nLast year, Vice President Biden said that with a new moonshot, America can cure cancer. Last month, he worked with this Congress to give scientists at the National Institutes of Health the strongest resources that they’ve had in over a decade. (Applause.) So tonight, I’m announcing a new national effort to get it done. And because he’s gone to the mat for all of us on so many issues over the past 40 years, I’m putting Joe in charge of Mission Control. (Applause.) For the loved ones we’ve all lost, for the families that we can still save, let’s make America the country that cures cancer once and for all. (Applause.)\\n\\nMedical research is critical. We need the same level of commitment when it comes to developing clean energy sources. (Applause.) Look, if anybody still wants to dispute the science around climate change, have at it. You will be pretty lonely, because you’ll be debating our military, most of America’s business leaders, the majority of the American people, almost the entire scientific community, and 200 nations around the world who agree it’s a problem and intend to solve it. (Applause.)\\n\\nBut even if -- even if the planet wasn’t at stake, even if 2014 wasn’t the warmest year on record -- until 2015 turned out to be even hotter -- why would we want to pass up the chance for American businesses to produce and sell the energy of the future? (Applause.)\\n\\nListen, seven years ago, we made the single biggest investment in clean energy in our history. Here are the results. In fields from Iowa to Texas, wind power is now cheaper than dirtier, conventional power. On rooftops from Arizona to New York, solar is saving Americans tens of millions of dollars a year on their energy bills, and employs more Americans than coal -- in jobs that pay better than average. We’re taking steps to give homeowners the freedom to generate and store their own energy -- something, by the way, that environmentalists and Tea Partiers have teamed up to support. And meanwhile, we’ve cut our imports of foreign oil by nearly 60 percent, and cut carbon pollution more than any other country on Earth. (Applause.)\\n\\nGas under two bucks a gallon ain’t bad, either. (Applause.)\\n\\nNow we’ve got to accelerate the transition away from old, dirtier energy sources. Rather than subsidize the past, we should invest in the future -- especially in communities that rely on fossil fuels. We do them no favor when we don't show them where the trends are going. That’s why I’m going to push to change the way we manage our oil and coal resources, so that they better reflect the costs they impose on taxpayers and our planet. And that way, we put money back into those communities, and put tens of thousands of Americans to work building a 21st century transportation system. (Applause.)\\n\\nNow, none of this is going to happen overnight. And, yes, there are plenty of entrenched interests who want to protect the status quo. But the jobs we’ll create, the money we’ll save, the planet we’ll preserve -- that is the kind of future our kids and our grandkids deserve. And it's within our grasp.\\n\\nClimate change is just one of many issues where our security is linked to the rest of the world. And that’s why the third big question that we have to answer together is how to keep America safe and strong without either isolating ourselves or trying to nation-build everywhere there’s a problem.\\n\\nI told you earlier all the talk of America’s economic decline is political hot air. Well, so is all the rhetoric you hear about our enemies getting stronger and America getting weaker. Let me tell you something. The United States of America is the most powerful nation on Earth. Period. (Applause.) Period. It’s not even close. It's not even close. (Applause.) It's not even close. We spend more on our military than the next eight nations combined. Our troops are the finest fighting force in the history of the world. (Applause.) No nation attacks us directly, or our allies, because they know that’s the path to ruin. Surveys show our standing around the world is higher than when I was elected to this office, and when it comes to every important international issue, people of the world do not look to Beijing or Moscow to lead -- they call us. (Applause.)\\n\\nI mean, it's useful to level the set here, because when we don't, we don't make good decisions.\\n\\nNow, as someone who begins every day with an intelligence briefing, I know this is a dangerous time. But that’s not primarily because of some looming superpower out there, and certainly not because of diminished American strength. In today’s world, we’re threatened less by evil empires and more by failing states.\\n\\nThe Middle East is going through a transformation that will play out for a generation, rooted in conflicts that date back millennia. Economic headwinds are blowing in from a Chinese economy that is in significant transition. Even as their economy severely contracts, Russia is pouring resources in to prop up Ukraine and Syria -- client states that they saw slipping away from their orbit. And the international system we built after World War II is now struggling to keep pace with this new reality.\\n\\nIt’s up to us, the United States of America, to help remake that system. And to do that well it means that we’ve got to set priorities.\\n\\nPriority number one is protecting the American people and going after terrorist networks. (Applause.) Both al Qaeda and now ISIL pose a direct threat to our people, because in today’s world, even a handful of terrorists who place no value on human life, including their own, can do a lot of damage. They use the Internet to poison the minds of individuals inside our country. Their actions undermine and destabilize our allies. We have to take them out./p>\\n\\nBut as we focus on destroying ISIL, over-the-top claims that this is World War III just play into their hands. Masses of fighters on the back of pickup trucks, twisted souls plotting in apartments or garages -- they pose an enormous danger to civilians; they have to be stopped. But they do not threaten our national existence. (Applause.) That is the story ISIL wants to tell. That’s the kind of propaganda they use to recruit. We don’t need to build them up to show that we’re serious, and we sure don't need to push away vital allies in this fight by echoing the lie that ISIL is somehow representative of one of the world’s largest religions. (Applause.) We just need to call them what they are -- killers and fanatics who have to be rooted out, hunted down, and destroyed. (Applause.)\\n\\nAnd that’s exactly what we’re doing. For more than a year, America has led a coalition of more than 60 countries to cut off ISIL’s financing, disrupt their plots, stop the flow of terrorist fighters, and stamp out their vicious ideology. With nearly 10,000 air strikes, we’re taking out their leadership, their oil, their training camps, their weapons. We’re training, arming, and supporting forces who are steadily reclaiming territory in Iraq and Syria.\\n\\nIf this Congress is serious about winning this war, and wants to send a message to our troops and the world, authorize the use of military force against ISIL. Take a vote. (Applause.) Take a vote. But the American people should know that with or without congressional action, ISIL will learn the same lessons as terrorists before them. If you doubt America’s commitment -- or mine -- to see that justice is done, just ask Osama bin Laden. (Applause.) Ask the leader of al Qaeda in Yemen, who was taken out last year, or the perpetrator of the Benghazi attacks, who sits in a prison cell. When you come after Americans, we go after you. (Applause.) And it may take time, but we have long memories, and our reach has no limits. (Applause.)\\n\\nOur foreign policy hast to be focused on the threat from ISIL and al Qaeda, but it can’t stop there. For even without ISIL, even without al Qaeda, instability will continue for decades in many parts of the world -- in the Middle East, in Afghanistan, parts of Pakistan, in parts of Central America, in Africa, and Asia. Some of these places may become safe havens for new terrorist networks. Others will just fall victim to ethnic conflict, or famine, feeding the next wave of refugees. The world will look to us to help solve these problems, and our answer needs to be more than tough talk or calls to carpet-bomb civilians. That may work as a TV sound bite, but it doesn’t pass muster on the world stage.\\n\\nWe also can’t try to take over and rebuild every country that falls into crisis, even if it's done with the best of intentions. (Applause.) That’s not leadership; that’s a recipe for quagmire, spilling American blood and treasure that ultimately will weaken us. It’s the lesson of Vietnam; it's the lesson of Iraq -- and we should have learned it by now. (Applause.)\\n\\nFortunately, there is a smarter approach, a patient and disciplined strategy that uses every element of our national power. It says America will always act, alone if necessary, to protect our people and our allies; but on issues of global concern, we will mobilize the world to work with us, and make sure other countries pull their own weight.\\n\\nThat’s our approach to conflicts like Syria, where we’re partnering with local forces and leading international efforts to help that broken society pursue a lasting peace.\\n\\nThat’s why we built a global coalition, with sanctions and principled diplomacy, to prevent a nuclear-armed Iran. And as we speak, Iran has rolled back its nuclear program, shipped out its uranium stockpile, and the world has avoided another war. (Applause.)\\n\\nThat’s how we stopped the spread of Ebola in West Africa. (Applause.) Our military, our doctors, our development workers -- they were heroic; they set up the platform that then allowed other countries to join in behind us and stamp out that epidemic. Hundreds of thousands, maybe a couple million lives were saved.\\n\\nThat’s how we forged a Trans-Pacific Partnership to open markets, and protect workers and the environment, and advance American leadership in Asia. It cuts 18,000 taxes on products made in America, which will then support more good jobs here in America. With TPP, China does not set the rules in that region; we do. You want to show our strength in this new century? Approve this agreement. Give us the tools to enforce it. It's the right thing to do. (Applause.)\\n\\nLet me give you another example. Fifty years of isolating Cuba had failed to promote democracy, and set us back in Latin America. That’s why we restored diplomatic relations -- (applause) -- opened the door to travel and commerce, positioned ourselves to improve the lives of the Cuban people. (Applause.) So if you want to consolidate our leadership and credibility in the hemisphere, recognize that the Cold War is over -- lift the embargo. (Applause.)\\n\\nThe point is American leadership in the 21st century is not a choice between ignoring the rest of the world -- except when we kill terrorists -- or occupying and rebuilding whatever society is unraveling. Leadership means a wise application of military power, and rallying the world behind causes that are right. It means seeing our foreign assistance as a part of our national security, not something separate, not charity.\\n\\nWhen we lead nearly 200 nations to the most ambitious agreement in history to fight climate change, yes, that helps vulnerable countries, but it also protects our kids. When we help Ukraine defend its democracy, or Colombia resolve a decades-long war, that strengthens the international order we depend on. When we help African countries feed their people and care for the sick -- (applause) -- it's the right thing to do, and it prevents the next pandemic from reaching our shores. Right now, we’re on track to end the scourge of HIV/AIDS. That's within our grasp. (Applause.) And we have the chance to accomplish the same thing with malaria -- something I’ll be pushing this Congress to fund this year. (Applause.)\\n\\nThat's American strength. That's American leadership. And that kind of leadership depends on the power of our example. That’s why I will keep working to shut down the prison at Guantanamo. (Applause.) It is expensive, it is unnecessary, and it only serves as a recruitment brochure for our enemies. (Applause.) There’s a better way. (Applause.)\\n\\nAnd that’s why we need to reject any politics -- any politics -- that targets people because of race or religion. (Applause.) Let me just say this. This is not a matter of political correctness. This is a matter of understanding just what it is that makes us strong. The world respects us not just for our arsenal; it respects us for our diversity, and our openness, and the way we respect every faith.\\n\\nHis Holiness, Pope Francis, told this body from the very spot that I'm standing on tonight that “to imitate the hatred and violence of tyrants and murderers is the best way to take their place.” When politicians insult Muslims, whether abroad or our fellow citizens, when a mosque is vandalized, or a kid is called names, that doesn’t make us safer. That’s not telling it like it is. It’s just wrong. (Applause.) It diminishes us in the eyes of the world. It makes it harder to achieve our goals. It betrays who we are as a country. (Applause.)\\n\\n“We the People.” Our Constitution begins with those three simple words, words we’ve come to recognize mean all the people, not just some; words that insist we rise and fall together, and that's how we might perfect our Union. And that brings me to the fourth, and maybe the most important thing that I want to say tonight.\\n\\nThe future we want -- all of us want -- opportunity and security for our families, a rising standard of living, a sustainable, peaceful planet for our kids -- all that is within our reach. But it will only happen if we work together. It will only happen if we can have rational, constructive debates. It will only happen if we fix our politics.\\n\\nA better politics doesn’t mean we have to agree on everything. This is a big country -- different regions, different attitudes, different interests. That’s one of our strengths, too. Our Founders distributed power between states and branches of government, and expected us to argue, just as they did, fiercely, over the size and shape of government, over commerce and foreign relations, over the meaning of liberty and the imperatives of security.\\n\\nBut democracy does require basic bonds of trust between its citizens. It doesn’t work if we think the people who disagree with us are all motivated by malice. It doesn’t work if we think that our political opponents are unpatriotic or trying to weaken America. Democracy grinds to a halt without a willingness to compromise, or when even basic facts are contested, or when we listen only to those who agree with us. Our public life withers when only the most extreme voices get all the attention. And most of all, democracy breaks down when the average person feels their voice doesn’t matter; that the system is rigged in favor of the rich or the powerful or some special interest.\\n\\nToo many Americans feel that way right now. It’s one of the few regrets of my presidency -- that the rancor and suspicion between the parties has gotten worse instead of better. I have no doubt a president with the gifts of Lincoln or Roosevelt might have better bridged the divide, and I guarantee I’ll keep trying to be better so long as I hold this office.\\n\\nBut, my fellow Americans, this cannot be my task -- or any President’s -- alone. There are a whole lot of folks in this chamber, good people who would like to see more cooperation, would like to see a more elevated debate in Washington, but feel trapped by the imperatives of getting elected, by the noise coming out of your base. I know; you’ve told me. It's the worst-kept secret in Washington. And a lot of you aren't enjoying being trapped in that kind of rancor.\\n\\nBut that means if we want a better politics -- and I'm addressing the American people now -- if we want a better politics, it’s not enough just to change a congressman or change a senator or even change a President. We have to change the system to reflect our better selves. I think we've got to end the practice of drawing our congressional districts so that politicians can pick their voters, and not the other way around. (Applause.) Let a bipartisan group do it. (Applause.)\\n\\nWe have to reduce the influence of money in our politics, so that a handful of families or hidden interests can’t bankroll our elections. (Applause.) And if our existing approach to campaign finance reform can’t pass muster in the courts, we need to work together to find a real solution -- because it's a problem. And most of you don't like raising money. I know; I've done it. (Applause.) We’ve got to make it easier to vote, not harder. (Applause.) We need to modernize it for the way we live now. (Applause.) This is America: We want to make it easier for people to participate. And over the course of this year, I intend to travel the country to push for reforms that do just that.\\n\\nBut I can’t do these things on my own. (Applause.) Changes in our political process -- in not just who gets elected, but how they get elected -- that will only happen when the American people demand it. It depends on you. That’s what’s meant by a government of, by, and for the people.\\n\\nWhat I’m suggesting is hard. It’s a lot easier to be cynical; to accept that change is not possible, and politics is hopeless, and the problem is all the folks who are elected don't care, and to believe that our voices and actions don’t matter. But if we give up now, then we forsake a better future. Those with money and power will gain greater control over the decisions that could send a young soldier to war, or allow another economic disaster, or roll back the equal rights and voting rights that generations of Americans have fought, even died, to secure. And then, as frustration grows, there will be voices urging us to fall back into our respective tribes, to scapegoat fellow citizens who don’t look like us, or pray like us, or vote like we do, or share the same background.\\n\\nWe can’t afford to go down that path. It won’t deliver the economy we want. It will not produce the security we want. But most of all, it contradicts everything that makes us the envy of the world.\\n\\nSo, my fellow Americans, whatever you may believe, whether you prefer one party or no party, whether you supported my agenda or fought as hard as you could against it -- our collective futures depends on your willingness to uphold your duties as a citizen. To vote. To speak out. To stand up for others, especially the weak, especially the vulnerable, knowing that each of us is only here because somebody, somewhere, stood up for us. (Applause.) We need every American to stay active in our public life -- and not just during election time -- so that our public life reflects the goodness and the decency that I see in the American people every single day.\\n\\nIt is not easy. Our brand of democracy is hard. But I can promise that a little over a year from now, when I no longer hold this office, I will be right there with you as a citizen, inspired by those voices of fairness and vision, of grit and good humor and kindness that helped America travel so far. Voices that help us see ourselves not, first and foremost, as black or white, or Asian or Latino, not as gay or straight, immigrant or native born, not as Democrat or Republican, but as Americans first, bound by a common creed. Voices Dr. King believed would have the final word -- voices of unarmed truth and unconditional love.\\n\\nAnd they’re out there, those voices. They don’t get a lot of attention; they don't seek a lot of fanfare; but they’re busy doing the work this country needs doing. I see them everywhere I travel in this incredible country of ours. I see you, the American people. And in your daily acts of citizenship, I see our future unfolding.\\n\\nI see it in the worker on the assembly line who clocked extra shifts to keep his company open, and the boss who pays him higher wages instead of laying him off.\\n\\nI see it in the Dreamer who stays up late to finish her science project, and the teacher who comes in early because he knows she might someday cure a disease.\\n\\nI see it in the American who served his time, and made mistakes as a child but now is dreaming of starting over -- and I see it in the business owner who gives him that second chance. The protester determined to prove that justice matters -- and the young cop walking the beat, treating everybody with respect, doing the brave, quiet work of keeping us safe. (Applause.)\\n\\nI see it in the soldier who gives almost everything to save his brothers, the nurse who tends to him till he can run a marathon, the community that lines up to cheer him on.\\n\\nIt’s the son who finds the courage to come out as who he is, and the father whose love for that son overrides everything he’s been taught. (Applause.)\\n\\nI see it in the elderly woman who will wait in line to cast her vote as long as she has to; the new citizen who casts his vote for the first time; the volunteers at the polls who believe every vote should count -- because each of them in different ways know how much that precious right is worth.\\n\\nThat's the America I know. That’s the country we love. Clear-eyed. Big-hearted. Undaunted by challenge. Optimistic that unarmed truth and unconditional love will have the final word. (Applause.) That’s what makes me so hopeful about our future. I believe in change because I believe in you, the American people.\\n\\nAnd that’s why I stand here confident as I have ever been that the State of our Union is strong. (Applause.)\\n\\nThank you, God bless you. God bless the United States of America.\", metadata={'source': 'speech.txt'})]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Ingestion\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"speech.txt\")\n",
    "text_document = loader.load()\n",
    "text_document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equips agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web based loader\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "# Load, chunk, and index the content of the html page\n",
    "loader = WebBaseLoader(web_path=\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "                       bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                           class_=(\"post-title\", \"post-content\", \"post-header\")\n",
    "                       ))\n",
    ")\n",
    "text_document = loader.load()\n",
    "text_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='                                                                                                               e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2796 ] \\nLANGCHAIN -POWERED VIRTUAL ASSISTANT FOR PDF  \\nCOMMUNICATION  \\nNR Tejaswini*1, Vidya S*2, Dr. T Vijaya Kumar*3 \\n*1Student , Master Of Computer Applications , Bangalore Institute Of Technology , Bangalore , India . \\n*2Assistant  Professor , Master Of Computer Applications , Bangalore Institute Of  \\nTechnology , Bangalore , India . \\n*3Professor , Master Of Computer Applications , Bangalore Institute Of Technology , Bangalore , India . \\nDOI : https://www.doi.org/10.56726/IRJMETS43587  \\nABSTRACT  \\nDue to the unstructured nature of the PDF document format and the requirement for precise and pertinent \\nsearch results, querying a PDF can take time and effort. LangChain overcomes these challenges by utilizing \\nadvanced natural language processing algorithms that analyze the content of the PDFs and extract essential \\ninformation. To improve the search experience, it uses effective indexing and retrieval techniques, movable \\nfilters  and a simple search int erface. LangChain also allows users to save queries, create bookmarks  and \\nannotate important sections, enabling efficient retrieval of relevant information from PDF documents. The \\nfeatures of LangChain increase overall efficiency and makes PDF querying muc h easier and simpler.  \\nKeywords : LangChain, Querying PDF, Machine Translation, Streamlit.  \\nI. INTRODUCTION  \\nThe increasing prevalence and usage of digital products have created challenges in searching and retrieving \\ninformation from PDF documents. However, a revolutionary tool called LangChain, built on Natural Language \\nProcessing (NLP) and Large Language Models (LLM), addresses these challenges. LangChain simplifies the \\nquerying process and information extraction from PDFs using advanced NLP algorithms. To cr eate a user -\\nfriendly interface, LangChain utilizes Streamlit, a web application framework that eliminates the need for \\nexpertise in other web development frameworks like HTML and CSS. Streamlit enables the seamless \\ndeployment of models with minimal coding effort. With LangChain and Streamlit, users can easily interact with \\nPDFs, making document search and retrieval significantly more convenient.  The PDF Query App Project uses \\nLanguage Models (LLMs) and LangChain, a cutting -edge language processing tool, to transform how users \\ninteract with PDF documents. By allowing users to have interactive conversations with PDF documents, this \\nproject solves the fundamental drawbacks of conventional PDF readers. This description highlights the problem \\nstatement and the so lution while also giving a general overview of the project.  \\nII. LITRATURE SURVEY  \\nThe literature review for the project \"LangChain PDF Query\" focuses on exploring relevant research and \\ntechnologies related to language models, natural language processing, AI advancements  and query systems.  \\nJonas Gehring et .al.,[1] In the realm of sequence -to-sequence learning, presented \"Convolutional Sequence to \\nSequence Learning,\" which showcased a novel approach to modeling sequences using convolutional neural \\nnetworks, of fering insights into how language structures can be better understood and represented.  Attention \\nmechanisms have revolutionized language models, as demonstrated in \"Attention Is All You Need\" by Ashish \\nVaswani et . al., [2]. Their transformative \"transforme r\" architecture enabled highly efficient and effective \\nattention -based models for various NLP tasks, paving the way for advanced query systems.  While exploring AI \\napplications in the legal domain, Jules Ioannidis et al. , [3] introduced \"Gracenote.ai,\" an A I system designed for \\nregulatory compliance. This research highlights the potential of generative AI in addressing complex legal \\nchallenges.  For specific use cases, Na He et al. , [4] showed that \"Chat GPT -4\" outperformed GPT -3.5 in drug \\ninformation queries , indicating the continuous advancements in language models for domain -specific \\ninformation retrieval.  Efficient keyword search over encrypted cloud data is crucial for data privacy and \\nsecurity. Anuradha & Patil ., [5] presented an approach for such search, contributing insights into secure \\ninformation retrieval in cloud environments.  ', metadata={'source': 'langchain-assist.pdf', 'page': 0}),\n",
       " Document(page_content='                                                                                                               e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2797 ] \\nAddressing the challenges of big data, Madhu Nashipudimath et al. , [6] proposed an integration and indexing \\nmethod based on feature patte rns and semantic analysis. This research offers valuable techniques to efficiently \\nmanage and query large datasets.  In the scientific literature domain, Zhu and Cole ., [7] developed a tool for \\nreading scientific text and interpreting metadata from typeset literature in PDF format. This tool demonstrates \\nadvancements in information extraction from scientific documents.  To implement the project, it is essential to \\nconsider the platforms and tools available. Streamlit ., [8] provides a user -friendly interface f or data \\nvisualization and interaction, while Python LangChain ., [9] offers comprehensive documentation for integrating \\nlanguage models into applications.  OpenAI\\'s models [10],  including GPT -3.5, serve as a crucial foundation for \\nlanguage -based AI applicati ons. Adith Sreeram A S and Pappuri Jithendra Sai , [11]  presented an effective query \\nsystem using language models and LangChain, which can be insightful for developing the LangChain PDF Query.  \\nIn conclusion, this literature review has provided a comprehensi ve understanding of the research and \\ntechnologies relevant to the project \"LangChain PDF Query.\" It covered sequence -to-sequence learning, \\nattention -based models, AI in legal compliance, domain -specific information retrieval, secure cloud data search, \\nbig data processing, scientific literature analysis  and essential tools for implementation. These valuable insights \\nwill guide the development of an efficient and effective query system using LangChain and language models, \\ncontributing to the advancement of AI -driven natural language processing.  \\nIII. METHODOLOGY  \\nLanChain helps us with the querying process and extracting information from the PDF based on the prompt \\nsent by the user. For the sake of convenience, a web application is developed that can retrieve accurate \\ninformation based on the user’s input alone.  \\n \\nFigure 1. Application Architecture  \\n2.1 Steps followed in the Application Architechture:  \\nStep l: The Open Al Large Language Models and The Open Al Embeddings acts as the back -end of our \\napplication.  \\nStep II: Here we will use Streamlit, which will help us to build interactive and beautiful interface for our web \\napplication.  \\nStep Ill: Streamlit will also take care of our Front -end part where we can get the text inputs and messages and \\nalso the PDF files from the user.  \\n', metadata={'source': 'langchain-assist.pdf', 'page': 1}),\n",
       " Document(page_content='                                                                                                               e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2798 ] \\n \\nFigure 2. Working Process.  \\nWith the help of Fig  2 we can understand how Larg e Language Model helps the user to get the accurate results.  \\n2.2 Streamlit  \\nStreamlit is an open -source library that allows us to unique web apps for Machine Learning and Data Science \\nprojects fast and efficient. Streamlit is an open -source library that allows us to unique web apps for Machine \\nLearning and Data Science projects fast and efficient. With this framework, you can easily build interactive \\nvisualizat ion plots, models  and dashboards without having a worry about the underlying web framework or \\ndeployment infrastructure used in the backend. It also provides the users to add widgets which helps the users \\nthe interact with the web app and the models that w e used. This framework also integrates the popular python \\nand machine learning packages such as NumPy, Pandas, Matplotlib, Seaborn, Scikit -learn and TensorFlow, \\nwhich enables us to quickly build and deploy our trained models. Features of Streamlit:  \\nUser -friendly:  Streamlit offers an easy -to-use interface that requires little scripting to build dynamic data apps.  \\nRapid prototyping:  Streamlit is made for rapid prototyping, allowing developers and data scientists to test out \\nvarious concepts and create comp letely functional apps.  \\nData Cache:  The data cache facilitates and accelerates computational workflows.  \\nReal -time collaboration is made possible by Streamlit, allowing several users to work on the same project at \\nonce. Widgets that enable for real -time d ata editing and exploration include sliders, dropdown menus  and \\ncheckboxes, among a vast variety of interactive widgets that Streamlit offers.  \\nIV. RESULTS AND DISCUSSIO N \\n \\nFigure 3 . Interface of web Tool  \\nThis is how the interface of our web Tool will look like. Now the user can click on browse files and can upload a \\nfile from their device under 200 Mega Bytes. After few minutes of processing, we will get an additional in box \\nwhere we can give in our query.  \\n', metadata={'source': 'langchain-assist.pdf', 'page': 2}),\n",
       " Document(page_content='                                                                                                               e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2799 ] \\n \\nFigure 4 . Image of web Tool with input query box.  \\nSo, now we got our input query box and now we can ask questions on the PDF that we have uploaded. Here I \\nhave uploaded a PDF based on Cloud Computing. Now you can ask differe nt questions like “What is cloud \\ncomputing?”, “What are the Architectural styles based on independent components?” and also differentiate \\nbetween questions.  \\n \\nFigure 5 . The Output that we got for our 1st Query  \\n \\nFigure 6 . The Output that we got for our 2 nd Query  \\n', metadata={'source': 'langchain-assist.pdf', 'page': 3}),\n",
       " Document(page_content='                                                                                                               e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2800 ] \\nHere we got our output for our 1st and 2nd query which is “What is Cloud Computing?” and “What are the \\nArchitectural styles based on independent components?” our Large Language Model went through file and gave \\nan accurate result on the query given.  \\n \\nFigure 7 . The output we got for Different Question  \\nThe output \"I don\\'t know the answer to  the question\" indicates that the Large Language Model couldn\\'t find an \\naccurate response to the query \"what is big data analytics?\" within the provided PDF. Despite analyzing the \\ncontent of the file, the model couldn\\'t retrieve a satisfactory result in relation to the specific query.  \\nV. CONCLUSION  \\nThe Tool that leverages LangChain, Large Language Models  and Streamlit to streamline the extraction of \\npertinent information from PDFs. This innovative solution significantly simplifies and enhances the process, \\nallowing users to retrieve any desired information from PDF documents while saving ti me and effort. By \\nintegrating LangChain technology, the app introduces a heightened level of efficiency and accuracy to the \\nquerying process, making it an invaluable tool for individuals working with PDFs. Users can effortlessly extract \\nrelevant data, impr oving productivity and reducing the manual effort traditionally required for PDF document \\nanalysis. The user -friendly interface and intuitive features provided by Streamlit further enhance the overall \\nuser experience. Our web application empowers users to efficiently navigate and retrieve information from \\nPDFs, transforming the way PDF querying is performed and revolutionizing the accessibility and usability of \\nPDF documents.  \\nVI. REFERENCES  \\n[1] Jonas Gehring,  Michael Auli,  David Grangier,  Denis Yarats,  Yann N. Dauphin: “Convolutional Sequence \\nto Sequence Learning”, arXiv: [v1] Mon, 8 May 2017 23:25:30 UTC (1,489 KB) [v2]  Fri,12May 2017 \\n16:14:26 UTC (492 KB) [v3]  Tue, 25 Jul 2017 01:40:57 UTC (492 KB).  \\n[2] Ashish  Vaswani, Noam Shazeer Niki Pannar, Jakob Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia \\nPolosukhin: “Attention Is All You Need” arXiv: [v1] Mon, 12 Jun 2017 17:57:34 UTC (1,102 \\nKB)[v2]  Mon, 19 Jun 2017  16:49:45 UTC (1,125 KB) [v3]  Tue, 20 Jun 2017 05:20:02 UTC (1,125 \\nKB)[v4]  Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB ) \\n[3] Jules Ioannidis, Joshua Harper, Min g Sheng Quah I and Dan Hunter I: “Gracenote.ai: Legal Generative AI \\nfor Regulatory Compliance” v1 Gracenote -ai- Melboume Australia v2 The Dlckson Poon School of Law, \\nKing\\'s College London, United Kingdom June 19, 2023.  \\n[4] Na He, Yingying Yan, Ziyang Wul C heng, Fang Liu:” Chat GPT -4 significantly surpasses GPT -3.5 in drug \\ninformation queries”, National Library of Medicine, June 2023.  \\n[5] Anuradha & Patil, G A (2016):” Efficient Keyword Search over Encrypted Cloud Data - Procedia \\nComputer Science.”, Science  Direct, Volume 78, 2016, Pages 139 -145,23 -02-2016.  \\n', metadata={'source': 'langchain-assist.pdf', 'page': 4}),\n",
       " Document(page_content='                                                                                                               e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2801 ] \\n[6] Madhu Nashipudimath, Subhash Shinde, Jayshree Jain: “An efficient integration and indexing method \\nbased on feature pattens and semantic analysis for big data.”, Research Gate,June 2020.  \\n[7] Zhu, Miao & Cole, Jacqueline. (2022): “A Tool for Reading Scientific Text and Interpreting Metadata \\nfrom the Typeset Literature in the Portable Document Format.” Joumal of Chemical Information and \\nModeling, March 29, 2022.  \\n[8] https://streamlit.io/ , May 2023.  \\n[9] https://python.langchain.com/docs/get_started/introduction.html , April 2023.  \\n[10] http s://platform.openai.com/docs/models , June 2023.  \\n[11] Adith Sreeram A S, Pappuri Jithendra Sai: “An Effective Query System Using LLMs and \\nLangChain”,  IJERT, olume 12, Issue 06 (June 2023).  \\n \\n ', metadata={'source': 'langchain-assist.pdf', 'page': 5})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PDF reader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path=\"langchain-assist.pdf\")\n",
    "pdf_document = loader.load()\n",
    "pdf_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2796 ] \\nLANGCHAIN -POWERED VIRTUAL ASSISTANT FOR PDF  \\nCOMMUNICATION  \\nNR Tejaswini*1, Vidya S*2, Dr. T Vijaya Kumar*3 \\n*1Student , Master Of Computer Applications , Bangalore Institute Of Technology , Bangalore , India . \\n*2Assistant  Professor , Master Of Computer Applications , Bangalore Institute Of  \\nTechnology , Bangalore , India .', metadata={'source': 'langchain-assist.pdf', 'page': 0}),\n",
       " Document(page_content='*2Assistant  Professor , Master Of Computer Applications , Bangalore Institute Of  \\nTechnology , Bangalore , India . \\n*3Professor , Master Of Computer Applications , Bangalore Institute Of Technology , Bangalore , India . \\nDOI : https://www.doi.org/10.56726/IRJMETS43587  \\nABSTRACT  \\nDue to the unstructured nature of the PDF document format and the requirement for precise and pertinent \\nsearch results, querying a PDF can take time and effort. LangChain overcomes these challenges by utilizing \\nadvanced natural language processing algorithms that analyze the content of the PDFs and extract essential \\ninformation. To improve the search experience, it uses effective indexing and retrieval techniques, movable \\nfilters  and a simple search int erface. LangChain also allows users to save queries, create bookmarks  and \\nannotate important sections, enabling efficient retrieval of relevant information from PDF documents. The', metadata={'source': 'langchain-assist.pdf', 'page': 0}),\n",
       " Document(page_content='annotate important sections, enabling efficient retrieval of relevant information from PDF documents. The \\nfeatures of LangChain increase overall efficiency and makes PDF querying muc h easier and simpler.  \\nKeywords : LangChain, Querying PDF, Machine Translation, Streamlit.  \\nI. INTRODUCTION  \\nThe increasing prevalence and usage of digital products have created challenges in searching and retrieving \\ninformation from PDF documents. However, a revolutionary tool called LangChain, built on Natural Language \\nProcessing (NLP) and Large Language Models (LLM), addresses these challenges. LangChain simplifies the \\nquerying process and information extraction from PDFs using advanced NLP algorithms. To cr eate a user -\\nfriendly interface, LangChain utilizes Streamlit, a web application framework that eliminates the need for \\nexpertise in other web development frameworks like HTML and CSS. Streamlit enables the seamless', metadata={'source': 'langchain-assist.pdf', 'page': 0}),\n",
       " Document(page_content='expertise in other web development frameworks like HTML and CSS. Streamlit enables the seamless \\ndeployment of models with minimal coding effort. With LangChain and Streamlit, users can easily interact with \\nPDFs, making document search and retrieval significantly more convenient.  The PDF Query App Project uses \\nLanguage Models (LLMs) and LangChain, a cutting -edge language processing tool, to transform how users \\ninteract with PDF documents. By allowing users to have interactive conversations with PDF documents, this \\nproject solves the fundamental drawbacks of conventional PDF readers. This description highlights the problem \\nstatement and the so lution while also giving a general overview of the project.  \\nII. LITRATURE SURVEY  \\nThe literature review for the project \"LangChain PDF Query\" focuses on exploring relevant research and \\ntechnologies related to language models, natural language processing, AI advancements  and query systems.', metadata={'source': 'langchain-assist.pdf', 'page': 0}),\n",
       " Document(page_content='technologies related to language models, natural language processing, AI advancements  and query systems.  \\nJonas Gehring et .al.,[1] In the realm of sequence -to-sequence learning, presented \"Convolutional Sequence to \\nSequence Learning,\" which showcased a novel approach to modeling sequences using convolutional neural \\nnetworks, of fering insights into how language structures can be better understood and represented.  Attention \\nmechanisms have revolutionized language models, as demonstrated in \"Attention Is All You Need\" by Ashish \\nVaswani et . al., [2]. Their transformative \"transforme r\" architecture enabled highly efficient and effective \\nattention -based models for various NLP tasks, paving the way for advanced query systems.  While exploring AI \\napplications in the legal domain, Jules Ioannidis et al. , [3] introduced \"Gracenote.ai,\" an A I system designed for \\nregulatory compliance. This research highlights the potential of generative AI in addressing complex legal', metadata={'source': 'langchain-assist.pdf', 'page': 0}),\n",
       " Document(page_content='regulatory compliance. This research highlights the potential of generative AI in addressing complex legal \\nchallenges.  For specific use cases, Na He et al. , [4] showed that \"Chat GPT -4\" outperformed GPT -3.5 in drug \\ninformation queries , indicating the continuous advancements in language models for domain -specific \\ninformation retrieval.  Efficient keyword search over encrypted cloud data is crucial for data privacy and \\nsecurity. Anuradha & Patil ., [5] presented an approach for such search, contributing insights into secure \\ninformation retrieval in cloud environments.', metadata={'source': 'langchain-assist.pdf', 'page': 0}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2797 ] \\nAddressing the challenges of big data, Madhu Nashipudimath et al. , [6] proposed an integration and indexing \\nmethod based on feature patte rns and semantic analysis. This research offers valuable techniques to efficiently \\nmanage and query large datasets.  In the scientific literature domain, Zhu and Cole ., [7] developed a tool for', metadata={'source': 'langchain-assist.pdf', 'page': 1}),\n",
       " Document(page_content=\"manage and query large datasets.  In the scientific literature domain, Zhu and Cole ., [7] developed a tool for \\nreading scientific text and interpreting metadata from typeset literature in PDF format. This tool demonstrates \\nadvancements in information extraction from scientific documents.  To implement the project, it is essential to \\nconsider the platforms and tools available. Streamlit ., [8] provides a user -friendly interface f or data \\nvisualization and interaction, while Python LangChain ., [9] offers comprehensive documentation for integrating \\nlanguage models into applications.  OpenAI's models [10],  including GPT -3.5, serve as a crucial foundation for \\nlanguage -based AI applicati ons. Adith Sreeram A S and Pappuri Jithendra Sai , [11]  presented an effective query \\nsystem using language models and LangChain, which can be insightful for developing the LangChain PDF Query.\", metadata={'source': 'langchain-assist.pdf', 'page': 1}),\n",
       " Document(page_content='system using language models and LangChain, which can be insightful for developing the LangChain PDF Query.  \\nIn conclusion, this literature review has provided a comprehensi ve understanding of the research and \\ntechnologies relevant to the project \"LangChain PDF Query.\" It covered sequence -to-sequence learning, \\nattention -based models, AI in legal compliance, domain -specific information retrieval, secure cloud data search, \\nbig data processing, scientific literature analysis  and essential tools for implementation. These valuable insights \\nwill guide the development of an efficient and effective query system using LangChain and language models, \\ncontributing to the advancement of AI -driven natural language processing.  \\nIII. METHODOLOGY  \\nLanChain helps us with the querying process and extracting information from the PDF based on the prompt \\nsent by the user. For the sake of convenience, a web application is developed that can retrieve accurate', metadata={'source': 'langchain-assist.pdf', 'page': 1}),\n",
       " Document(page_content='sent by the user. For the sake of convenience, a web application is developed that can retrieve accurate \\ninformation based on the user’s input alone.  \\n \\nFigure 1. Application Architecture  \\n2.1 Steps followed in the Application Architechture:  \\nStep l: The Open Al Large Language Models and The Open Al Embeddings acts as the back -end of our \\napplication.  \\nStep II: Here we will use Streamlit, which will help us to build interactive and beautiful interface for our web \\napplication.  \\nStep Ill: Streamlit will also take care of our Front -end part where we can get the text inputs and messages and \\nalso the PDF files from the user.', metadata={'source': 'langchain-assist.pdf', 'page': 1}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2798 ] \\n \\nFigure 2. Working Process.  \\nWith the help of Fig  2 we can understand how Larg e Language Model helps the user to get the accurate results.  \\n2.2 Streamlit  \\nStreamlit is an open -source library that allows us to unique web apps for Machine Learning and Data Science \\nprojects fast and efficient. Streamlit is an open -source library that allows us to unique web apps for Machine', metadata={'source': 'langchain-assist.pdf', 'page': 2}),\n",
       " Document(page_content='projects fast and efficient. Streamlit is an open -source library that allows us to unique web apps for Machine \\nLearning and Data Science projects fast and efficient. With this framework, you can easily build interactive \\nvisualizat ion plots, models  and dashboards without having a worry about the underlying web framework or \\ndeployment infrastructure used in the backend. It also provides the users to add widgets which helps the users \\nthe interact with the web app and the models that w e used. This framework also integrates the popular python \\nand machine learning packages such as NumPy, Pandas, Matplotlib, Seaborn, Scikit -learn and TensorFlow, \\nwhich enables us to quickly build and deploy our trained models. Features of Streamlit:  \\nUser -friendly:  Streamlit offers an easy -to-use interface that requires little scripting to build dynamic data apps.  \\nRapid prototyping:  Streamlit is made for rapid prototyping, allowing developers and data scientists to test out', metadata={'source': 'langchain-assist.pdf', 'page': 2}),\n",
       " Document(page_content='Rapid prototyping:  Streamlit is made for rapid prototyping, allowing developers and data scientists to test out \\nvarious concepts and create comp letely functional apps.  \\nData Cache:  The data cache facilitates and accelerates computational workflows.  \\nReal -time collaboration is made possible by Streamlit, allowing several users to work on the same project at \\nonce. Widgets that enable for real -time d ata editing and exploration include sliders, dropdown menus  and \\ncheckboxes, among a vast variety of interactive widgets that Streamlit offers.  \\nIV. RESULTS AND DISCUSSIO N \\n \\nFigure 3 . Interface of web Tool  \\nThis is how the interface of our web Tool will look like. Now the user can click on browse files and can upload a \\nfile from their device under 200 Mega Bytes. After few minutes of processing, we will get an additional in box \\nwhere we can give in our query.', metadata={'source': 'langchain-assist.pdf', 'page': 2}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2799 ] \\n \\nFigure 4 . Image of web Tool with input query box.  \\nSo, now we got our input query box and now we can ask questions on the PDF that we have uploaded. Here I \\nhave uploaded a PDF based on Cloud Computing. Now you can ask differe nt questions like “What is cloud \\ncomputing?”, “What are the Architectural styles based on independent components?” and also differentiate \\nbetween questions.', metadata={'source': 'langchain-assist.pdf', 'page': 3}),\n",
       " Document(page_content='computing?”, “What are the Architectural styles based on independent components?” and also differentiate \\nbetween questions.  \\n \\nFigure 5 . The Output that we got for our 1st Query  \\n \\nFigure 6 . The Output that we got for our 2 nd Query', metadata={'source': 'langchain-assist.pdf', 'page': 3}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2800 ] \\nHere we got our output for our 1st and 2nd query which is “What is Cloud Computing?” and “What are the \\nArchitectural styles based on independent components?” our Large Language Model went through file and gave \\nan accurate result on the query given.  \\n \\nFigure 7 . The output we got for Different Question', metadata={'source': 'langchain-assist.pdf', 'page': 4}),\n",
       " Document(page_content='an accurate result on the query given.  \\n \\nFigure 7 . The output we got for Different Question  \\nThe output \"I don\\'t know the answer to  the question\" indicates that the Large Language Model couldn\\'t find an \\naccurate response to the query \"what is big data analytics?\" within the provided PDF. Despite analyzing the \\ncontent of the file, the model couldn\\'t retrieve a satisfactory result in relation to the specific query.  \\nV. CONCLUSION  \\nThe Tool that leverages LangChain, Large Language Models  and Streamlit to streamline the extraction of \\npertinent information from PDFs. This innovative solution significantly simplifies and enhances the process, \\nallowing users to retrieve any desired information from PDF documents while saving ti me and effort. By \\nintegrating LangChain technology, the app introduces a heightened level of efficiency and accuracy to the \\nquerying process, making it an invaluable tool for individuals working with PDFs. Users can effortlessly extract', metadata={'source': 'langchain-assist.pdf', 'page': 4}),\n",
       " Document(page_content='querying process, making it an invaluable tool for individuals working with PDFs. Users can effortlessly extract \\nrelevant data, impr oving productivity and reducing the manual effort traditionally required for PDF document \\nanalysis. The user -friendly interface and intuitive features provided by Streamlit further enhance the overall \\nuser experience. Our web application empowers users to efficiently navigate and retrieve information from \\nPDFs, transforming the way PDF querying is performed and revolutionizing the accessibility and usability of \\nPDF documents.  \\nVI. REFERENCES  \\n[1] Jonas Gehring,  Michael Auli,  David Grangier,  Denis Yarats,  Yann N. Dauphin: “Convolutional Sequence \\nto Sequence Learning”, arXiv: [v1] Mon, 8 May 2017 23:25:30 UTC (1,489 KB) [v2]  Fri,12May 2017 \\n16:14:26 UTC (492 KB) [v3]  Tue, 25 Jul 2017 01:40:57 UTC (492 KB).  \\n[2] Ashish  Vaswani, Noam Shazeer Niki Pannar, Jakob Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia', metadata={'source': 'langchain-assist.pdf', 'page': 4}),\n",
       " Document(page_content=\"16:14:26 UTC (492 KB) [v3]  Tue, 25 Jul 2017 01:40:57 UTC (492 KB).  \\n[2] Ashish  Vaswani, Noam Shazeer Niki Pannar, Jakob Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia \\nPolosukhin: “Attention Is All You Need” arXiv: [v1] Mon, 12 Jun 2017 17:57:34 UTC (1,102 \\nKB)[v2]  Mon, 19 Jun 2017  16:49:45 UTC (1,125 KB) [v3]  Tue, 20 Jun 2017 05:20:02 UTC (1,125 \\nKB)[v4]  Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB ) \\n[3] Jules Ioannidis, Joshua Harper, Min g Sheng Quah I and Dan Hunter I: “Gracenote.ai: Legal Generative AI \\nfor Regulatory Compliance” v1 Gracenote -ai- Melboume Australia v2 The Dlckson Poon School of Law, \\nKing's College London, United Kingdom June 19, 2023.  \\n[4] Na He, Yingying Yan, Ziyang Wul C heng, Fang Liu:” Chat GPT -4 significantly surpasses GPT -3.5 in drug \\ninformation queries”, National Library of Medicine, June 2023.  \\n[5] Anuradha & Patil, G A (2016):” Efficient Keyword Search over Encrypted Cloud Data - Procedia\", metadata={'source': 'langchain-assist.pdf', 'page': 4}),\n",
       " Document(page_content='information queries”, National Library of Medicine, June 2023.  \\n[5] Anuradha & Patil, G A (2016):” Efficient Keyword Search over Encrypted Cloud Data - Procedia \\nComputer Science.”, Science  Direct, Volume 78, 2016, Pages 139 -145,23 -02-2016.', metadata={'source': 'langchain-assist.pdf', 'page': 4}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2801 ] \\n[6] Madhu Nashipudimath, Subhash Shinde, Jayshree Jain: “An efficient integration and indexing method \\nbased on feature pattens and semantic analysis for big data.”, Research Gate,June 2020.  \\n[7] Zhu, Miao & Cole, Jacqueline. (2022): “A Tool for Reading Scientific Text and Interpreting Metadata \\nfrom the Typeset Literature in the Portable Document Format.” Joumal of Chemical Information and', metadata={'source': 'langchain-assist.pdf', 'page': 5}),\n",
       " Document(page_content='from the Typeset Literature in the Portable Document Format.” Joumal of Chemical Information and \\nModeling, March 29, 2022.  \\n[8] https://streamlit.io/ , May 2023.  \\n[9] https://python.langchain.com/docs/get_started/introduction.html , April 2023.  \\n[10] http s://platform.openai.com/docs/models , June 2023.  \\n[11] Adith Sreeram A S, Pappuri Jithendra Sai: “An Effective Query System Using LLMs and \\nLangChain”,  IJERT, olume 12, Issue 06 (June 2023).', metadata={'source': 'langchain-assist.pdf', 'page': 5})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the pdf document into chunks\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(pdf_document)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Embeddings and Vector Store\n",
    "\n",
    "# Chroma Vectore Database\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(documents[:20], OpenAIEmbeddings()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2800 ] \\nHere we got our output for our 1st and 2nd query which is “What is Cloud Computing?” and “What are the \\nArchitectural styles based on independent components?” our Large Language Model went through file and gave \\nan accurate result on the query given.  \\n \\nFigure 7 . The output we got for Different Question', metadata={'page': 4, 'source': 'langchain-assist.pdf'}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2796 ] \\nLANGCHAIN -POWERED VIRTUAL ASSISTANT FOR PDF  \\nCOMMUNICATION  \\nNR Tejaswini*1, Vidya S*2, Dr. T Vijaya Kumar*3 \\n*1Student , Master Of Computer Applications , Bangalore Institute Of Technology , Bangalore , India . \\n*2Assistant  Professor , Master Of Computer Applications , Bangalore Institute Of  \\nTechnology , Bangalore , India .', metadata={'page': 0, 'source': 'langchain-assist.pdf'}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2799 ] \\n \\nFigure 4 . Image of web Tool with input query box.  \\nSo, now we got our input query box and now we can ask questions on the PDF that we have uploaded. Here I \\nhave uploaded a PDF based on Cloud Computing. Now you can ask differe nt questions like “What is cloud \\ncomputing?”, “What are the Architectural styles based on independent components?” and also differentiate \\nbetween questions.', metadata={'page': 3, 'source': 'langchain-assist.pdf'}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2797 ] \\nAddressing the challenges of big data, Madhu Nashipudimath et al. , [6] proposed an integration and indexing \\nmethod based on feature patte rns and semantic analysis. This research offers valuable techniques to efficiently \\nmanage and query large datasets.  In the scientific literature domain, Zhu and Cole ., [7] developed a tool for', metadata={'page': 1, 'source': 'langchain-assist.pdf'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query = \"Who are the authors of this research paper?\"\n",
    "result = db.similarity_search(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS Vector database\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "db_1 = FAISS.from_documents(documents[:20], OpenAIEmbeddings())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2800 ] \\nHere we got our output for our 1st and 2nd query which is “What is Cloud Computing?” and “What are the \\nArchitectural styles based on independent components?” our Large Language Model went through file and gave \\nan accurate result on the query given.  \\n \\nFigure 7 . The output we got for Different Question', metadata={'source': 'langchain-assist.pdf', 'page': 4}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2796 ] \\nLANGCHAIN -POWERED VIRTUAL ASSISTANT FOR PDF  \\nCOMMUNICATION  \\nNR Tejaswini*1, Vidya S*2, Dr. T Vijaya Kumar*3 \\n*1Student , Master Of Computer Applications , Bangalore Institute Of Technology , Bangalore , India . \\n*2Assistant  Professor , Master Of Computer Applications , Bangalore Institute Of  \\nTechnology , Bangalore , India .', metadata={'source': 'langchain-assist.pdf', 'page': 0}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2799 ] \\n \\nFigure 4 . Image of web Tool with input query box.  \\nSo, now we got our input query box and now we can ask questions on the PDF that we have uploaded. Here I \\nhave uploaded a PDF based on Cloud Computing. Now you can ask differe nt questions like “What is cloud \\ncomputing?”, “What are the Architectural styles based on independent components?” and also differentiate \\nbetween questions.', metadata={'source': 'langchain-assist.pdf', 'page': 3}),\n",
       " Document(page_content='e-ISSN: 2582 -5208 \\nInternatio nal  Research Journal  of  Modernization in Engineering Technology  and  Science  \\n( Peer -Reviewed, Open Access, Fully Refereed International Journal )  \\nVolume:05/Issue:07/July -2023                   Impact Factor - 7.868                                    www .irjmets.com                        \\nwww.irjmets.com                               @International Research Journal of Modernization in Engineering, Technology and Science  \\n [2797 ] \\nAddressing the challenges of big data, Madhu Nashipudimath et al. , [6] proposed an integration and indexing \\nmethod based on feature patte rns and semantic analysis. This research offers valuable techniques to efficiently \\nmanage and query large datasets.  In the scientific literature domain, Zhu and Cole ., [7] developed a tool for', metadata={'source': 'langchain-assist.pdf', 'page': 1})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who are the authors of this research paper?\"\n",
    "result = db_1.similarity_search(query)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
